{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('yellow_tripdata_2021-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count FLOAT(53), \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" FLOAT(53), \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53), \n",
      "\tairport_fee FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1369769"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136976"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data chunk loaded into Postgres, 100000 took 57.2944757938385 seconds.\n",
      "Data chunk loaded into Postgres, 200000 took 69.67735028266907 seconds.\n",
      "Data chunk loaded into Postgres, 300000 took 62.468098878860474 seconds.\n",
      "Data chunk loaded into Postgres, 400000 took 71.75419020652771 seconds.\n",
      "Data chunk loaded into Postgres, 500000 took 71.46275877952576 seconds.\n",
      "Data chunk loaded into Postgres, 600000 took 93.13785815238953 seconds.\n",
      "Data chunk loaded into Postgres, 700000 took 90.75780701637268 seconds.\n",
      "Data chunk loaded into Postgres, 800000 took 95.60393905639648 seconds.\n",
      "Data chunk loaded into Postgres, 900000 took 60.382002115249634 seconds.\n",
      "Data chunk loaded into Postgres, 1000000 took 80.33531212806702 seconds.\n",
      "Data chunk loaded into Postgres, 1100000 took 53.98822236061096 seconds.\n",
      "Data chunk loaded into Postgres, 1200000 took 56.70489001274109 seconds.\n",
      "Data chunk loaded into Postgres, 1300000 took 62.49046778678894 seconds.\n",
      "Data chunk loaded into Postgres, 1369769 took 31.01853609085083 seconds.\n"
     ]
    }
   ],
   "source": [
    "chunksize = 100000\n",
    "\n",
    "for i in range(len(df)//chunksize + 1):\n",
    "    start = time()\n",
    "    df_iter = df[(i*100000):(i + 1)*100000]\n",
    "    \n",
    "    if i == 0:\n",
    "        df_iter.to_sql('yellow_taxi_data', con=engine, if_exists = 'replace', method='multi')\n",
    "    else:\n",
    "        df_iter.to_sql('yellow_taxi_data', con=engine, if_exists = 'append', method='multi')\n",
    "    end = time()\n",
    "    \n",
    "    print(f'Data chunk loaded into Postgres, {len(df_iter) + i*chunksize} records took {end - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
